## HTTP/2 与 HTTP/1.1

1. 当前的网络应用的趋势:

* 消息变大,请求数据的数量级变大
* 页面资源变多
* 内容形式变多样
* 实时性要求变高

2. HTTP/1.1 存在的性能缺陷

* 高延迟: 页面访问速度下降

网络延迟主要是队头阻塞导致,HTTP/1.1引入了管道机制,即在同一个TCP连接里面,客户端可以同时发送多个请求,进一步改进HTTP协议的效率。

但这要求服务端必须按照请求发送的顺序返回响应,当顺序请求多个文件,其中有一个文件因为某种原因被阻塞时,在后面排队的请求也一并被阻塞,
这就是队头阻塞.队头阻塞导致再大的带宽无法被充分利用.

缓解队头阻塞问题的方案:

(1) 引入雪碧图, 多个资源请求合并成一个; 使用base64格式的图片;

(2) 使用多个域名,因为同一域名的最大连接数有限制;

(3) 使用webpack的时候,可以将多个不频繁变化的js打包成一个js, 按需加载,懒加载,避免同一时刻请求过多的资源;

* 明文传输: 不安全

HTTP/1.1 在传输数据时,所有传输的内容都是明文,客户端和服务器都无法验证对方的身份,在一定程度上无法保证数据的安全性,有中间人攻击的风险.

* 无状态: 头部巨大且重复

由于HTTP是无状态的,每一个请求都得携带HTTP头部,特鄙视对于有携带cookie的头部,有些cookie可能会很大,另外User Agent, Accept, Server等,通常多大几百字节甚至上千字节,但body通常只有几十字节.

* 不支持服务器推送

HTTP/1.1 不支持服务器推送消息,这会导致一些带宽和服务器资源的浪费.

3. HTTP/2.0 新特性

HTTP/2.0 相比 HTTP/1.1, 能带来 20% ~ 60% 的访问速度的提升

* 二进制传输

HTTP/2.0 在应用层和传输层之间增加了一个二进制分帧层. 同域名下的所有通信都在单个连接上完成,该连接可以承载任意数量的双向数据流.每个数据流都以消息的形式发送.而消息又由一个或多个帧组成.多个帧之间可以乱序发送,根据帧首部的流标识可以重新组装.


* header 压缩

有些请求,头部较大,且很多字段都是重复的,每次携带,浪费带宽.HTTP/2.0引入了头部压缩机制,以方便,头部信息用gzip或者compress压缩后在发送.另一方面,客户端和服务器同时维护一张头信息表,所有字段都会存入,生成一个索引号,这样同样字段不会重复发送.

* 多路复用

建立一个请求,发送多条数据请求.有效避免了队头阻塞,也解决了同域名下最大请求数的限制问题.

* 数据流
HTTP/2.0将每个请求或回应的所有数据包,称为一个数据流.每个数据流都有一个独一无二的编号.数据包发送的时候,都必须标记数据流ID,用来区分那个数据流.

另还规定,客户端发出的数据流,ID一律为奇数,服务器发出的,ID为偶数.

数据流发到一半的时候,客户端和服务器都可以发送信号,取消这个数据流的发送和接收. 1.1版本取消数据流的唯一方法就是断开TCP连接，但是HTTP2可以取消单个请求的数据传输，同时保证TCP连接正常，可以继续被其他请求使用.

* **优先级**

HTTP/2.0,每个请求都可以带一个31bit的有限制,0表示最高优先级,数值越大优先级越低,有了这个优先级,客户端和服务器可以以最优的方式发送流,消息和帧.

* 服务端push

HTTP/2.0允许服务器未经请求,主动向客户端发送资源,这叫服务器推送.客户端可以根据是否需要来接收或者拒绝接收.主动推送也遵循同源策略,只会推送与当前域名相同的资源.

**HTTP/2.0 可以实现加密传输,安全性更高**

为何TCP连接的建立消耗带宽资源?  因为TCP是慢启动的.那么问题来了,什么是慢启动?

4. HTTP/2.0 的缺陷

* HTTP/2.0 如果出现丢包,整个TCP 的数据都要重传.

* TCP： TCP + TLS 握手比较费时,这个问题应该 HTTP/1.1 也存在.

5. 关于TCP的慢启动

为了避免网络拥塞,TCP采用了慢启动机制,传输开始时将发送窗口慢慢指数级扩大,传输过程中的窗口大小也会根据网络情况调整,从而避免一开始就传输大量数据导致网络拥塞.

6. HTTP3.0协议

由于TCP本身存在一些限制，google开发了一个基于UDP的QUIC协议，用在了HTTP3.0上。QUIC协议在UDP协议上实现了多路复用、有序交付、重传等功能。





