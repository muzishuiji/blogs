## HTTP/2 与 HTTP/1.1

1. 当前的网络应用的趋势:

* 消息变大,请求数据的数量级变大
* 页面资源变多
* 内容形式变多样
* 实时性要求变高

2. HTTP/1.1 存在的性能缺陷

* 高延迟: 页面访问速度下降

网络延迟主要是队头阻塞导致,HTTP/1.1引入了管道机制,即在同一个TCP连接里面,客户端可以同时发送多个请求,进一步改进HTTP协议的效率。

但这要求服务端必须按照请求发送的顺序返回响应,当顺序请求多个文件,其中有一个文件因为某种原因被阻塞时,在后面排队的请求也一并被阻塞,
这就是队头阻塞.队头阻塞导致再大的带宽无法被充分利用.

缓解队头阻塞问题的方案:

(1) 引入雪碧图, 多个资源请求合并成一个; 使用base64格式的图片;

(2) 使用多个域名,因为同一域名的最大连接数有限制;

(3) 使用webpack的时候,可以将多个不频繁变化的js打包成一个js, 按需加载,懒加载,避免同一时刻请求过多的资源;

* 明文传输: 不安全

HTTP/1.1 在传输数据时,所有传输的内容都是明文,客户端和服务器都无法验证对方的身份,在一定程度上无法保证数据的安全性,有中间人攻击的风险.

* 无状态: 头部巨大且重复

由于HTTP是无状态的,每一个请求都得携带HTTP头部,特鄙视对于有携带cookie的头部,有些cookie可能会很大,另外User Agent, Accept, Server等,通常多大几百字节甚至上千字节,但body通常只有几十字节.

* 不支持服务器推送

HTTP/1.1 不支持服务器推送消息,这会导致一些带宽和服务器资源的浪费.

3. HTTP/2.0 新特性

HTTP/2.0 相比 HTTP/1.1, 能带来 20% ~ 60% 的访问速度的提升

* 二进制传输

HTTP/2.0 在应用层和传输层之间增加了一个二进制分帧层. 同域名下的所有通信都在单个连接上完成,该连接可以承载任意数量的双向数据流.每个数据流都以消息的形式发送.而消息又由一个或多个帧组成.多个帧之间可以乱序发送,根据帧首部的流标识可以重新组装.


* header 压缩

有些请求,头部较大,且很多字段都是重复的,每次携带,浪费带宽.HTTP/2.0引入了头部压缩机制,一方面,头部信息用gzip或者compress压缩后在发送.另一方面,客户端和服务器同时维护一张头信息表,所有字段都会存入,生成一个索引号,这样同样字段不会重复发送.

* 多路复用

建立一个请求,发送多条数据请求.有效避免了队头阻塞,也解决了同域名下最大请求数的限制问题.

* 数据流
HTTP/2.0将每个请求或回应的所有数据包,称为一个数据流.每个数据流都有一个独一无二的编号.数据包发送的时候,都必须标记数据流ID,用来区分哪个数据流.

另还规定,客户端发出的数据流,ID一律为奇数,服务器发出的,ID为偶数.

数据流发到一半的时候,客户端和服务器都可以发送信号,取消这个数据流的发送和接收. 1.1版本取消数据流的唯一方法就是断开TCP连接，但是HTTP2可以取消单个请求的数据传输，同时保证TCP连接正常，可以继续被其他请求使用.

* **优先级**

HTTP/2.0,每个请求都可以带一个31bit的有限制,0表示最高优先级,数值越大优先级越低,有了这个优先级,客户端和服务器可以以最优的方式发送流,消息和帧.

优先级信息通过帧的权重和依赖关系传递。

* 服务端push

HTTP/2.0允许服务器未经请求,主动向客户端发送资源,这叫服务器推送.客户端可以根据是否需要来接收或者拒绝接收.主动推送也遵循同源策略,只会推送与当前域名相同的资源.

**HTTP/2.0 可以实现加密传输,安全性更高**

为何TCP连接的建立消耗带宽资源?  因为TCP是慢启动的.那么问题来了,什么是慢启动?

4. HTTP/2.0 的缺陷
  * HTTP/2.0 如果出现丢包,整个TCP 的数据都要重传.
  * TCP： TCP + TLS 握手比较费时,这个问题应该 HTTP/1.1 也存在.

5. 关于TCP的慢启动
为了避免网络拥塞,TCP采用了慢启动机制,传输开始时将发送窗口慢慢指数级扩大,传输过程中的窗口大小也会根据网络情况调整,从而避免一开始就传输大量数据导致网络拥塞.

6. HTTP3.0协议

由于TCP本身存在一些限制，google开发了一个基于UDP的QUIC协议，用在了HTTP3.0上。QUIC协议在UDP协议上实现了多路复用、有序交付、重传等功能。

7. http2.0存在的问题
  1. TCP队头阻塞
  HTTP2.0在单个TCP连接上实现了多路复用，允许多个请求和响应并行传输，一定程度上缓解了HTTP1.0协议的队头阻塞问题。
  然而，TCP协议本身是面向字节流的，如果某个数据包丢失，TCP会等待数据包重传，导致后续数据包被阻塞。
    - 在高丢包率的网络环境下，HTTP2.0的性能会显著下降；
    - 即使只有一个数据包丢失，也会影响整个连接中的所有流；
  2. 连接建立延迟
  HTTP2仍然基于TCP协议，而TCP需要需要经过三次握手才能建立连接。此外，TLS握手（用于HTTPS）也会增加额外的延迟。
    - 在首次连接时，延迟较高，尤其是在高延迟的网络环境下；
    - 对于短链接场景（如加载大量小资源），连接建立的开销较大；
  3. 服务器推送的局限性
  HTTP2引入了服务器推送功能，允许服务器主动向客户端推送资源。然而，服务器推送存在以下问题：
    - 推送的资源可能已经被缓存：客户端可能已经缓存了推送的资源，导致宽带浪费；
    - 推送优先级问题：服务器无法准确预测客户端需要的资源优先级；
    - 实现复杂性：服务器推送需要服务器和客户端的协同支持，实现和调试较为复杂；
  服务器推送的实际效果可能不如预期，甚至可能导致性能下降。
  4. 头部压缩的潜在风险
  HTTP2使用hpack算法对HTTP头部进行压缩，以减少头部的大小。然而，hpack压缩存在以下问题：
    - 压缩上下文攻击：攻击者可能通过操作压缩上下文，导致服务器或客户端的内存消耗增加；
    - 实现复杂性：hpack的实现较为复杂，可能导致兼容性问题；
  5. 多路复用的资源竞争
  HTTP2的多路复用允许多个请求和响应在同一个TCP连接上并行传输。然而，多个流之间可能会竞争带宽和资源，导致优先级较低的流被阻塞。
    - 在高负载的情况下，优先级较低的请求可能会被延迟；
    - 需要复杂的优先级调度机制来优化资源分配；

8. Http2.0和http3.0对比之前的版本，分别做了哪些改进？
  1. http/1.x的局限性
  在http/2和http/3之前，http/1.x主要存在以下问题：
    - 队头阻塞：每个TCP连接只能处理一个请求，必须等待前一个请求完成后才能发送下一个请求；
    - 高延迟：由于需要建立多个TCP连接来并行加载资源，增加了延迟；
    - 低效的头部传输：HTTP头部是纯文本格式，每次请求都需要重复发送相同的头部信息；
    - 缺乏优先级：无法指定资源的加载优先级；
  2. http/2的改进
    - 改进点：HTTP/2引入了二进制分帧层，将请求和响应分解为更小的帧；
    - 支持多路复用，允许在同一个TCP连接上并行传输多个请求和响应；
      - 多路复用解决了HTTP/1.x的队头阻塞问题；
      - 减少了TCP连接的数量，降低传输延迟；
    - 头部压缩：使用hpack算法对HTTP头部进行压缩。
      - 减少了头部的大小，节省带宽；
      - 避免了重复传输相同的头部信息；
    - 服务端推送：服务器可以主动向客户端推送资源，而无需客户端明确请求；
      - 减少了额外的请求延迟；
      - 提升了页面加载速度；
    - 允许客户端为请求设置优先级；
      - 确保关键资源优先加载；
      - 优化了页面渲染性能；

  3. HTTP/3的改进
    - HTTP/3使用QUIC协议代替TCP作为传输层协议；
      - 解决了TCP的队头阻塞问题；
      - 提供了更低的延迟和更高的可靠性；
    - 零RTT连接：QUIC支持0-RTT（零往返时间）连接，允许客户端在首次连接时立即发送数据；
      - 减少了连接建立的延迟；
      - 提升了首次加载的性能；
    - 改进拥塞控制：QUIC内置了更先进的拥塞控制算法。
      - 更好的适应网络变化；
      - 提升了在高延迟和不稳定网络下的性能；
    - 连接迁移：QUIC支持连接迁移，允许客户端在网络切换时保持连接；
      - 提升了移动设备上的用户体验；
      - 避免了因网络切换导致的连接中断；
    - 安全性：QUIC默认使用TLS1.3加密；
      - 提供了更强的安全性；
      - 减少了加密握手的时间；

9. http2.0的服务端推送

对使用HTTP2.0的服务端推送进行分析的结果不尽相同，没有明显的净性能提升，在很多情况下还会导致性能下降。这个功能会在chrome106及其他基于Chromium的浏览器的后续版本中默认暂停使用；

HTTP2.0的服务器推送的替代方案：
  - 103 early hints：103 early hints是一种不太容易出错的替代方案，具有与推送一样的许多优点，但缺点要少得多。103 early hints不会由服务端推送资源，而是仅向浏览器发送可能受益于立即请求的资源的提示。这样，浏览器就可以控制是否需要这些资源，从而制定性能更佳的加载决策；
  - 预加载关键资源：预加载关键资源是让网页和浏览器协同工作的另一种替代方案，以便在网页加载初期提前加载关键资源。虽然这确实需要先发送网页本身，因此速度不如网页推送或提前提示快，但它又一个额外的好处，即不会延迟关键网页资源；

10. QUIC协议具体是指什么？

QUIC协议使用UDP作为传输层协议。尽管UDP本身是不可靠的（不保证数据包的顺序、可靠性和完整性），但QUIC在UDP之上实现了一套可靠的传输机制，确保了数据的可靠传输。

  1. QUIC的核心机制：
    - 数据包重传：QUIC为每个数据包分配唯一的序列号，并在接收端确认收到的数据包。如果发送端未收到确认，则会重传丢失的数据包。从而确保数据包的可靠传输；
    - 确认机制（ACK）：接收端将会定期发送ACK，告知发送端已经成功接收的数据包，发送端可以根据确认帧判断是否需要重传；
    - 流量控制：QUIC实现了基于流的流量控制，限制了每个流的数据传输速率，防止接收端被过多的数据淹没。避免网络拥塞和数据丢失。
    - 拥塞控制：QUIC内置了先进的拥塞控制算法，动态调整发送速率以适应网络状况；在高延迟或者网络不稳定的情况下，保持高效的数据传输；
    - 数据包排序：QUCIC使用校验和检测数据包是否损坏，并通过重传机制恢复丢失或损坏的数据包；确保数据的完整性和可靠性；
  2. QUIC的可靠性的实现细节：
    - 连接建立：QUIC在连接建立时使用tls1.3进行加密握手，确保连接的安全性；
    - 支持0-RTT和1-RTT握手，减少连接建立的延迟；
    0-RTT（零往返时间），首次连接时立即发送数据。
    - 流的概念：QUIC引入了流的概念，每个流是一个独立的、有序的字节流；每个流都有自己的序列号和确认机制，确保数据的可靠传输；
    - 多路复用：QUIC支持在同一个连接上并行传输多个流，每个流独立处理；即使某个流的数据包丢失，不会影响其他流的传输（解决了队头阻塞的问题）。
    - 快速重传：QUIC实现了快速重传的机制，当检测到数据包丢失时，立即重传，而不需要等待超时；
    - 前向纠错：QUIC支持前向纠错机制，通过发送冗余数据包，使接收端能够在部分数据包丢失时恢复原始数据；进一步提高了数据传输的可靠性；

11. TCP和UDP最大的区别是什么？

**TCP（传输控制协议）** 和 **UDP（用户数据报协议）** 是两种最常用的传输层协议，它们在设计目标、特性和适用场景上有显著区别。以下是 TCP 和 UDP 的最大区别及其详细对比：

**连接方式**
  - TCP
    - **面向连接**：在数据传输之前，需要通过三次握手建立连接。
    - **可靠性**：确保数据按顺序、完整地传输。
    - **适用场景**：适用于需要可靠传输的场景，如文件传输、网页浏览、电子邮件等。

  - UDP
    - **无连接**：无需建立连接，直接发送数据。
    - **不可靠性**：不保证数据的顺序、完整性和可靠性。
    - **适用场景**：适用于实时性要求高、允许少量数据丢失的场景，如视频流、在线游戏、DNS 查询等。

**可靠性**
  - TCP
    - **可靠传输**：通过确认机制（ACK）、重传机制和序列号确保数据可靠传输。
    - **数据完整性**：通过校验和检测数据是否损坏，并重传损坏的数据包。

  - UDP
    - **不可靠传输**：不提供确认机制、重传机制和序列号。
    - **数据可能丢失**：数据包可能丢失、重复或乱序。

**数据传输方式**
  - TCP
    - **字节流传输**：将数据视为连续的字节流，没有明确的消息边界。
    - **分段和重组**：将大数据分段传输，并在接收端重组。
  - UDP
    - **数据报传输**：将数据封装为独立的数据报，每个数据报有明确的消息边界。
    - **不分段**：每个数据报作为一个整体发送和接收。

**性能**
  - TCP
    - **开销较大**：由于需要建立连接、确认和重传，TCP 的开销较大。
    - **延迟较高**：在丢包或网络拥塞时，TCP 会降低传输速率，导致延迟增加。

  - UDP
    - **开销较小**：无需建立连接和确认，UDP 的开销较小。
    - **延迟较低**：适合实时性要求高的应用，如视频会议和在线游戏。

**流量控制和拥塞控制**
  - TCP
    - **流量控制**：通过滑动窗口机制控制发送速率，避免接收端缓冲区溢出。
    - **拥塞控制**：通过拥塞窗口和算法（如慢启动、拥塞避免）动态调整发送速率。

  - UDP
    - **无流量控制**：不提供流量控制机制，可能导致接收端缓冲区溢出。
    - **无拥塞控制**：不提供拥塞控制机制，可能导致网络拥塞。
**头部开销**
  - TCP
    - **头部较大**：TCP 头部至少 20 字节，包含序列号、确认号、窗口大小等信息。
    - **适用场景**：适合传输大量数据的场景。

  - UDP
    - **头部较小**：UDP 头部仅 8 字节，包含源端口、目标端口、长度和校验和。
    - **适用场景**：适合传输小数据包的场景。
**应用场景**
  - TCP
    - **需要可靠传输的场景**：
      - 文件传输（FTP、HTTP）。
      - 电子邮件（SMTP、IMAP）。
      - 网页浏览（HTTP/HTTPS）。
    - 数据库访问。

  - UDP
    - **实时性要求高的场景**：
      - 视频流（如 YouTube、Netflix）。
      - 在线游戏。
      - 语音通话（如 VoIP）。
      - DNS 查询。